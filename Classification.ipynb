{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6317eb",
   "metadata": {},
   "source": [
    "# Классификация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "958e0b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# импортируем нужные библиотеки и структуры данных\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split #разделение на выборки\n",
    "from sklearn.tree import DecisionTreeClassifier #дерево решений\n",
    "from sklearn.ensemble import RandomForestClassifier #случайный лес\n",
    "from sklearn.linear_model import LogisticRegression #логистическая регрессия\n",
    "\n",
    "df = pd.read_csv('users_behavior.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be03d3e",
   "metadata": {},
   "source": [
    "В данном датасете содержатся данные о клиентах \"Мегалайн\", которые уже перешли на какой-то из тарифов:\n",
    "\n",
    "1. Количество звонков за месяц\n",
    "2. Количество минут за месяц\n",
    "3. Количество сообщений за месяц\n",
    "4. Количество потраченных мегабайт за месяц\n",
    "5. Факт подключения тарифа ultra (1 - подключён ultra, 0 - smart)\n",
    "\n",
    "Датасет был предоставлен уже предобработанным, поэтому можно приступать к разбиению данных на выборки и работой с моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a776e010",
   "metadata": {},
   "source": [
    "Перед созданием и работой с моделями, разобьём имеющиеся данные на три выборки: обучающую, валидационную и тестовую. Выбираться они будут в соотношении 60:20:20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd5906a",
   "metadata": {},
   "source": [
    "Для начала выделим в датасете признаки и целевой признак, которые будут записаны в переменных features и target соответственно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "debfc4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#выделим обычные признаки и целевые\n",
    "features = df.drop('is_ultra', axis=1)\n",
    "target = df['is_ultra']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80917fa3",
   "metadata": {},
   "source": [
    "После дважды применим функцию train_test_split библиотеки sklearn. В первый раз в соотношении 80 на 20, где 80 процентов занимают обучающая и валидационная выборки и 20 - тестовая. Во второй раз в соотношении 75 к 25, где 75 процентов придётся на обучающую выборку и 25 на валидационную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7e6ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки: 1928\n",
      "Размер валидационной выборки: 643\n",
      "Размер тестовой выборки: 643\n"
     ]
    }
   ],
   "source": [
    "# делим выборки на обучающую+валидационную и тестовую\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, \n",
    "                                                                            target, \n",
    "                                                                            test_size=0.2, \n",
    "                                                                            random_state=12189)\n",
    "\n",
    "# обучаюшую+валидационную делим между собой\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(features_train, \n",
    "                                                                              target_train, \n",
    "                                                                              test_size=0.25, \n",
    "                                                                              random_state=12189)\n",
    "\n",
    "# проверяем размеры выборок\n",
    "print('Размер обучающей выборки:', len(target_train))\n",
    "print('Размер валидационной выборки:', len(target_valid))\n",
    "print('Размер тестовой выборки:', len(target_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a7b413",
   "metadata": {},
   "source": [
    "### Дерево решений"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c0f918",
   "metadata": {},
   "source": [
    "Самая простая модель - это дерево решений. Она обучается быстрее всех вышеперечисленных, но имеет наименьшую точность.\n",
    "\n",
    "Для того, чтобы создать данную модель, импортируем структуру данных 'DecisionTreeClassifier' из библиотеки sklearn и создадим объект этой структуры.\n",
    "\n",
    "Точность модели будет проверена при различных значениях (от 1 до 10). Среди результатов будет выбрана наибольшая."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51c37959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наибольшая точность модели дерева решений на валидационной выборке: 0.8087091757387247\n"
     ]
    }
   ],
   "source": [
    "# задаём переменные для определения лучшей модели и лучшего результата точности на валидационной выборке\n",
    "best_model_tree = None #лучшая модель\n",
    "best_result_tree = 0 #лучшая точность\n",
    "\n",
    "# обучаем модель на обучающей выборке и выбираем оптимальную глубину (при которой будет наибольшая точность)\n",
    "for depth in range(1, 11):\n",
    "    model_tree = DecisionTreeClassifier(random_state=12189, max_depth=depth) # создаём объект структуры дерева решений\n",
    "    model_tree.fit(features_train, target_train)\n",
    "    result = model_tree.score(features_valid, target_valid)\n",
    "    if result > best_result_tree:\n",
    "        best_model_tree = model_tree\n",
    "        best_result_tree = result\n",
    "        \n",
    "print('Наибольшая точность модели дерева решений на валидационной выборке:', best_result_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94eaa55",
   "metadata": {},
   "source": [
    "### Случайный лес"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4231f6f",
   "metadata": {},
   "source": [
    "Случайный лес по своей сути является объединением нескольких деревьев решений. Обучается намного дольше, потому что работа идёт с несколькими деревьями, но точность будет выше, чем у просто дерева.\n",
    "\n",
    "Для того, чтобы создать модель случайного леса, импортируем структуру 'RandomForestClassifier' из библиотеки sklearn и создадим объект этой структуры.\n",
    "\n",
    "Точность модели будет проверена при разном количестве деревьев (10, 20, 30, 40 и 50) с разной глубиной (от 1 до 10). Среди них будет выбрана модель с наибольшим результатом правильных предсказаний на валидационной выборке.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5019ace1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наибольшая точность модели случайного леса на валидационной выборке: 0.8211508553654744\n"
     ]
    }
   ],
   "source": [
    "# задаём переменные для определения лучшей модели и лучшего результата точности на валидационной выборке\n",
    "best_model_forest = None\n",
    "best_result_forest = 0\n",
    "\n",
    "# обучаем модель на обучающей выборке и выбираем опттимальную глубину и количество деревьев, которые покажут лучший результат\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range(1, 11):\n",
    "        model_forest = RandomForestClassifier(random_state=12189, max_depth=depth, n_estimators=est)\n",
    "        model_forest.fit(features_train, target_train)\n",
    "        result = model_forest.score(features_valid, target_valid)\n",
    "        if result > best_result_forest:\n",
    "            best_model_forest = model_forest\n",
    "            best_result_forest = result\n",
    "            \n",
    "print('Наибольшая точность модели случайного леса на валидационной выборке:', best_result_forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2146478f",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672e1256",
   "metadata": {},
   "source": [
    "Логистическая регрессия по своей скорости обучения и точности будет чем-то средним между деревом решений и случайным лесом.\n",
    "\n",
    "Для того, чтобы создать модель логистической регрессии, импортируем структуру 'LogisticRegression' из библиотеки sklearn и создадим обхект этой структуры.\n",
    "\n",
    "У данной модели мало параметров, которые можно менять, поэтому мы проверим её точность только при параметрах по умолчанию.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdca0dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность модели логистической регресси на валидационной выборке: 0.7744945567651633\n"
     ]
    }
   ],
   "source": [
    "# обучаем модель на обучающей выборке\n",
    "best_model_logistic = LogisticRegression(random_state=12189)\n",
    "best_model_logistic.fit(features_train, target_train)\n",
    "result = best_model_logistic.score(features_valid, target_valid)\n",
    "\n",
    "# для удобства сохраняем результаты в других переменных\n",
    "best_result_logistic = result\n",
    "\n",
    "print('Точность модели логистической регресси на валидационной выборке:', best_result_logistic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048c01df",
   "metadata": {},
   "source": [
    "### Итог"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9367dcd",
   "metadata": {},
   "source": [
    "На валидационной выборке лучшую точность показала модель случайного леса. Поэтому проверим её на тестовой выборке.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "638d2562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7916018662519441"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_forest.score(features_test, target_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e8ccd",
   "metadata": {},
   "source": [
    "Точность предсказаний немного упала, но всё равно держится на достаточно высоком уровне.\n",
    "\n",
    "Проверив работу модели на тестовой выборке, приходим к тому, что лучше всего себя в данной задаче показывает модель случайного леса."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
